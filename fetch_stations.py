import requests  
import json  
import pandas as pd  
import time  
import os  
import pykakasi # è¿½åŠ   
  
# ä¿å­˜å…ˆ  
DATA_DIR = "data"  
os.makedirs(DATA_DIR, exist_ok=True)  
  
# å¤‰æ›å™¨ã®åˆæœŸåŒ–  
kks = pykakasi.kakasi()  
  
# å¯¾è±¡ã‚¨ãƒªã‚¢  
PREFECTURES = ["æ±äº¬éƒ½", "ç¥å¥ˆå·çœŒ", "åŸ¼ç‰çœŒ", "åƒè‘‰çœŒ", "èŒ¨åŸçœŒ", "æ ƒæœ¨çœŒ", "ç¾¤é¦¬çœŒ"]  
  
def to_hiragana(text):  
    """ æ¼¢å­—ã‚’ã²ã‚‰ãŒãªã«å¤‰æ›ã™ã‚‹ """  
    result = kks.convert(text)  
    return "".join([item['hira'] for item in result])  
  
def fetch_kanto_stations():  
    print("ğŸš€ é–¢æ±å…¨åŸŸã®é§…ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼†ã²ã‚‰ãŒãªå¤‰æ›ä¸­...")  
      
    all_stations = []  
    seen_ids = set()   
  
    for pref in PREFECTURES:  
        print(f"ğŸ“¡ {pref} å–å¾—ä¸­...")  
          
        # 1. è·¯ç·šä¸€è¦§  
        url = "https://express.heartrails.com/api/json"  
        try:  
            res = requests.get(url, params={"method": "getLines", "prefecture": pref}).json()  
            lines = res['response']['line']  
        except:  
            continue  
  
        for line in lines:  
            # 2. é§…ä¸€è¦§  
            try:  
                res_st = requests.get(url, params={"method": "getStations", "line": line}).json()  
                stations = res_st['response']['station']  
            except:  
                continue  
  
            for st in stations:  
                name = st['name']  
                line_name = st['line']  
                  
                # ãƒ¦ãƒ‹ãƒ¼ã‚¯ID (é§…å_è·¯ç·šå)  
                # Backendã®æ¤œç´¢ã§ä½¿ã†IDã¨ä¸€è‡´ã•ã›ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™  
                # ä»Šå›ã¯ã‚·ãƒ³ãƒ—ãƒ«ã«ã€Œé§…åã€ã‚’IDã¨ã—ã¾ã™ãŒã€åŒåé§…ï¼ˆæ–°å®¿ã®JRã¨å°ç”°æ€¥ãªã©ï¼‰ã¯  
                # æœ¬æ¥åŒºåˆ¥ã™ã¹ãã§ã™ãŒã€æ¤œç´¢ã®åˆ©ä¾¿æ€§é‡è¦–ã§çµ±åˆã—ã¾ã™  
                  
                # ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ç”¨ãƒ‡ãƒ¼ã‚¿ä½œæˆ  
                # ã²ã‚‰ãŒãªã‚’è‡ªå‹•ç”Ÿæˆ  
                kana = to_hiragana(name)  
                  
                # é‡è¤‡ãƒã‚§ãƒƒã‚¯ï¼ˆåŒã˜é§…åãŒåˆ¥ã®è·¯ç·šã§å‡ºã¦ãã¦ã‚‚ã€ãƒªã‚¹ãƒˆã«ã¯1ã¤ã‚ã‚Œã°è‰¯ã„å ´åˆã¨ã€åˆ†ã‘ãŸã„å ´åˆãŒã‚ã‚‹ï¼‰  
                # ã“ã“ã§ã¯ã€Œé§…å+è·¯ç·šã€ã‚’ãƒ¦ãƒ‹ãƒ¼ã‚¯ã‚­ãƒ¼ã¨ã—ã¦å…¨ä»¶ä¿å­˜ã—ã¾ã™  
                unique_key = f"{name}_{line_name}"  
                  
                if unique_key not in seen_ids:  
                    all_stations.append({  
                        "id": name,         # ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰æ¤œç´¢ç”¨ID (æ¼¢å­—)  
                        "n": name,          # è¡¨ç¤ºå  
                        "k": kana,          # æ¤œç´¢ç”¨ã‹ãª  
                        "l": line_name,     # è·¯ç·šå  
                        "lat": float(st['y']),  
                        "lon": float(st['x'])  
                    })  
                    seen_ids.add(unique_key)  
              
            time.sleep(0.1) # ãƒãƒŠãƒ¼å¾…æ©Ÿ  
  
    print(f"âœ… åˆè¨ˆ {len(all_stations)} é§…ã®ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ã¾ã—ãŸï¼")  
    return all_stations  
  
if __name__ == "__main__":  
    stations = fetch_kanto_stations()  
      
    # 1. ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ç”¨ (stations_kanto.json)  
    # index.html ãŒèª­ã¿è¾¼ã‚€  
    frontend_data = []  
    for s in stations:  
        frontend_data.append({  
            "n": s["n"],  
            "k": s["k"],  
            "l": s["l"]  
        })  
      
    with open(f"{DATA_DIR}/stations_kanto.json", "w", encoding="utf-8") as f:  
        json.dump(frontend_data, f, ensure_ascii=False, separators=(',', ':'))  
    print(f"ğŸ’¾ {DATA_DIR}/stations_kanto.json (å…¥åŠ›å€™è£œç”¨)")  
  
    # 2. ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ç”¨ (stops.txt)  
    # core_engine.py ãŒèª­ã¿è¾¼ã‚€  
    # é‡è¤‡ã™ã‚‹é§…åï¼ˆè·¯ç·šé•ã„ï¼‰ã¯ã€åº§æ¨™ã‚’å¹³å‡ã™ã‚‹ã‹ã€ä»£è¡¨åœ°ç‚¹ã‚’å–ã‚‹ã¹ãã§ã™ãŒ  
    # ä»Šå›ã¯ã€Œä¸Šæ›¸ãã€ã§æœ€æ–°ã®ã‚‚ã®ã‚’æ¡ç”¨ã—ã¾ã™ï¼ˆç°¡æ˜“å®Ÿè£…ï¼‰  
    unique_stops = {}  
    for s in stations:  
        unique_stops[s["id"]] = {  
            "stop_id": s["id"],  
            "stop_name": s["n"],  
            "stop_lat": s["lat"],  
            "stop_lon": s["lon"]  
        }  
      
    df = pd.DataFrame(list(unique_stops.values()))  
    df.to_csv(f"{DATA_DIR}/stops.txt", index=False)  
    print(f"ğŸ’¾ {DATA_DIR}/stops.txt (åº§æ¨™è¨ˆç®—ç”¨)")  