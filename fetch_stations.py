import requests  
import json  
import pandas as pd  
import time  
import os  
  
# ä¿å­˜å…ˆ  
DATA_DIR = "data"  
os.makedirs(DATA_DIR, exist_ok=True)  
  
# å¯¾è±¡ã‚¨ãƒªã‚¢ï¼ˆé–¢æ±1éƒ½6çœŒï¼‰  
PREFECTURES = ["æ±äº¬éƒ½", "ç¥å¥ˆå·çœŒ", "åŸ¼ç‰çœŒ", "åƒè‘‰çœŒ", "èŒ¨åŸçœŒ", "æ ƒæœ¨çœŒ", "ç¾¤é¦¬çœŒ"]  
  
def fetch_kanto_stations():  
    print("ğŸš€ é–¢æ±å…¨åŸŸã®é§…ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™...")  
      
    all_stations = []  
    seen_keys = set() # é‡è¤‡é™¤å»ç”¨  
  
    for pref in PREFECTURES:  
        print(f"ğŸ“¡ {pref} ã®è·¯ç·šã‚’å–å¾—ä¸­...")  
          
        # 1. ãã®çœŒã®è·¯ç·šä¸€è¦§ã‚’å–å¾—  
        url_lines = "https://express.heartrails.com/api/json"  
        params_lines = {"method": "getLines", "prefecture": pref}  
          
        try:  
            res_lines = requests.get(url_lines, params=params_lines).json()  
            lines = res_lines['response']['line']  
        except Exception as e:  
            print(f"Error fetching lines for {pref}: {e}")  
            continue  
  
        for line in lines:  
            # print(f"  - {line} ã®é§…ã‚’å–å¾—ä¸­...")  
              
            # 2. ãã®è·¯ç·šã®é§…ä¸€è¦§ã‚’å–å¾—  
            params_stations = {"method": "getStations", "line": line}  
            try:  
                res_st = requests.get(url_lines, params=params_stations).json()  
                stations = res_st['response']['station']  
            except Exception as e:  
                continue  
  
            for st in stations:  
                # å¿…è¦ãªãƒ‡ãƒ¼ã‚¿ã ã‘æŠ½å‡º  
                name = st['name']  
                line_name = st['line']  
                lat = float(st['y'])  
                lon = float(st['x'])  
                # èª­ã¿ä»®å (APIã«ã‚ˆã£ã¦ã¯å–ã‚Œãªã„å ´åˆã‚‚ã‚ã‚‹ãŒã€HeartRailsã¯ 'prev' 'next' ç­‰ã—ã‹ãªã„ã®ã§ã€  
                # ã“ã“ã§ã¯ç°¡æ˜“çš„ã«ã²ã‚‰ãŒãªå¤‰æ›ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ä½¿ã†ã‹ã€ä»Šå›ã¯ã€Œæ¼¢å­—æ¤œç´¢ã€ã‚’ä¸»ã¨ã™ã‚‹)  
                # â€»HeartRailsã«ã¯ã€Œãµã‚ŠãŒãªã€ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒãªã„ãŸã‚ã€æ¤œç´¢ç”¨ã«ã€Œã²ã‚‰ãŒãªã€ã¯ä½œã‚Œã¾ã›ã‚“ã€‚  
                # ä»£ã‚ã‚Šã«ã€Œãã®ã¾ã¾ã®åå‰ã€ã§ç™»éŒ²ã—ã¾ã™ã€‚  
                  
                # ãƒ¦ãƒ‹ãƒ¼ã‚¯IDä½œæˆ (é§…å+è·¯ç·šå)  
                unique_id = f"{name}_{line_name}"  
                  
                # é‡è¤‡ãƒã‚§ãƒƒã‚¯ï¼ˆå±±æ‰‹ç·šã®æ–°å®¿ã¨ä¸­å¤®ç·šã®æ–°å®¿ãªã©ï¼‰  
                # ã‚¢ãƒ—ãƒªã®æ¤œç´¢ç”¨ã«ã¯ã€Œè·¯ç·šåè¾¼ã¿ã€ã§åˆ¥ã€…ã«ç™»éŒ²ã—ãŸã„  
                  
                # ãƒ‡ãƒ¼ã‚¿æ•´å½¢  
                station_data = {  
                    "name": name,  
                    "line": line_name,  
                    "lat": lat,  
                    "lon": lon,  
                    # IDã¯è‹±èªã§ã‚ã‚‹å¿…è¦ã¯ãªã„ã®ã§ã€ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªæ–‡å­—åˆ—ã«ã™ã‚‹  
                    "id": unique_id  
                }  
                  
                # ãƒªã‚¹ãƒˆã«è¿½åŠ   
                if unique_id not in seen_keys:  
                    all_stations.append(station_data)  
                    seen_keys.add(unique_id)  
              
            # ã‚µãƒ¼ãƒãƒ¼ã«å„ªã—ãï¼ˆçŸ­æ™‚é–“å¾…æ©Ÿï¼‰  
            time.sleep(0.1)  
  
    print(f"âœ… åˆè¨ˆ {len(all_stations)} é§…ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¾ã—ãŸï¼")  
    return all_stations  
  
if __name__ == "__main__":  
    stations = fetch_kanto_stations()  
      
    # === 1. ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ç”¨ (JSON) ===  
    # index.html ãŒèª­ã¿è¾¼ã‚€ãŸã‚ã®ãƒ•ã‚¡ã‚¤ãƒ«  
    # æ¤œç´¢ã—ã‚„ã™ã„ã‚ˆã†ã«ç°¡ç•¥åŒ–  
    frontend_data = []  
    for s in stations:  
        frontend_data.append({  
            "n": s["name"],  
            "l": s["line"],  
            "id": s["id"]  
        })  
      
    with open(f"{DATA_DIR}/stations_kanto.json", "w", encoding="utf-8") as f:  
        json.dump(frontend_data, f, ensure_ascii=False, separators=(',', ':'))  
    print(f"ğŸ’¾ {DATA_DIR}/stations_kanto.json ã‚’ä¿å­˜ã—ã¾ã—ãŸ (ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ç”¨)")  
  
    # === 2. ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ç”¨ (stops.txt) ===  
    # core_engine.py ãŒèª­ã¿è¾¼ã‚€ãŸã‚ã®CSV  
    df = pd.DataFrame([{  
        "stop_id": s["id"],  
        "stop_name": s["name"],  
        "stop_lat": s["lat"],  
        "stop_lon": s["lon"]  
    } for s in stations])  
      
    df.to_csv(f"{DATA_DIR}/stops.txt", index=False)  
    print(f"ğŸ’¾ {DATA_DIR}/stops.txt ã‚’ä¿å­˜ã—ã¾ã—ãŸ (ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ç”¨)")  
      
    print("\nğŸ‰ ãƒ‡ãƒ¼ã‚¿æ›´æ–°å®Œäº†ï¼")  
    print("æ³¨æ„: stop_times.txt (æ™‚åˆ»è¡¨) ã¯ã¾ã ãƒ‹ã‚»ãƒ¢ãƒã®ã¾ã¾ã§ã™ã€‚")  
    print("é§…ãŒå¢—ãˆãŸã®ã§ã€æ¤œç´¢è‡ªä½“ã¯ã§ãã¾ã™ãŒã€çµŒè·¯ï¼ˆæ™‚åˆ»è¡¨ï¼‰ãŒãªã„é§…ã¸ã®ãƒ«ãƒ¼ãƒˆã¯å‡ºã¾ã›ã‚“ã€‚")  